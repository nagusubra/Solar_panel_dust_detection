{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nagusubra/Solar_panel_dust_detection/blob/main/Solar_panel_dust_detection_compression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQAMdUOp9lRn"
      },
      "source": [
        "#Install libraries and modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLxJiY6u9Zh0",
        "outputId": "9376ee51-ad46-4f1e-e206-6264ee2eb402"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.2 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.9/dist-packages (3.0.10)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.9/dist-packages (from openpyxl) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.0.9-py3-none-any.whl (152 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.0.9\n"
          ]
        }
      ],
      "source": [
        "!pip install -q tensorflow-model-optimization\n",
        "!pip install openpyxl\n",
        "!pip install xlsxwriter\n",
        "\n",
        "import xlsxwriter\n",
        "import openpyxl\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.drawing.image import Image\n",
        "\n",
        "import tempfile\n",
        "from tensorflow import keras\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qeqtoyTCppFF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, Dropout\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "import tensorflow_datasets as tfds\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WVnbwh-9x2l",
        "outputId": "3da573c1-c977-41c8-e8d7-7bfe1875689e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mounting google drive (if you are using Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjpFrB77S6QU"
      },
      "source": [
        "# Evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oB55zL05S_Oe"
      },
      "outputs": [],
      "source": [
        "# Evaluate Model Size\n",
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "\n",
        "def evaluate_model(model_path, model_info, val_dataset):\n",
        "\n",
        "  # Evaluate test accuracy and test loss\n",
        "  model = tf.keras.models.load_model(model_path)\n",
        "  test_loss, test_acc = model.evaluate(val_dataset, verbose=0)\n",
        "\n",
        "  # Evaluate Model Size\n",
        "  model_size = get_gzipped_model_size(model_path)\n",
        "\n",
        "  # Evaluate Inference Time\n",
        "  startTime = time.time()\n",
        "  prediction = model.predict(val_dataset)\n",
        "  executionTime = (time.time() - startTime)/len(val_dataset)\n",
        "\n",
        "  # Print\n",
        "  print('\\nModel Accuracy:', test_acc*100, '%')\n",
        "  print(\"Model Size: %.2f bytes\" % (model_size))\n",
        "  print(\"Inference Time is: \", executionTime, \"s\")\n",
        "\n",
        "  # Build Evalution dataframe\n",
        "  evulation_dict = {\n",
        "                      \"Evaluation type\": \"Evualation\",\n",
        "                      \"Model Information\": model_info,\n",
        "                      \"Accuracy\": str(test_acc*100) + \" %\",\n",
        "                      \"Loss\": str(test_loss*100) + \" %\",\n",
        "                      \"Model Size\": str(model_size) + \" bytes\",\n",
        "                      \"Inference Time\": str(executionTime) + \" sec\"\n",
        "                    }\n",
        "  \n",
        "  evulation_df = pd.DataFrame.from_dict(evulation_dict, orient='index').reset_index()\n",
        "\n",
        "\n",
        "  return test_acc, model_size, executionTime, evulation_df\n",
        "\n",
        "\n",
        "def evaluate_model_without_saving_stats(model, model_path, model_info, val_dataset):\n",
        "\n",
        "  # Evaluate test accuracy and test loss\n",
        "  # model = tf.keras.models.load_model(model_path)\n",
        "  test_loss, test_acc = model.evaluate(val_dataset, verbose=0)\n",
        "\n",
        "  # Evaluate Model Size\n",
        "  model_size = get_gzipped_model_size(model_path)\n",
        "\n",
        "  # Evaluate Inference Time\n",
        "  startTime = time.time()\n",
        "  prediction = model.predict(val_dataset)\n",
        "  executionTime = (time.time() - startTime)/len(val_dataset)\n",
        "\n",
        "  # Print\n",
        "  print('\\nModel Accuracy:', test_acc*100, '%')\n",
        "  print(\"Model Size: %.2f bytes\" % (model_size))\n",
        "  print(\"Inference Time is: \", executionTime, \"s\")\n",
        "\n",
        "  # Build Evalution dataframe\n",
        "  evulation_dict = {\n",
        "                      \"Evaluation type\": \"Evualation\",\n",
        "                      \"Model Information\": model_info,\n",
        "                      \"Accuracy\": str(test_acc*100) + \" %\",\n",
        "                      \"Loss\": str(test_loss*100) + \" %\",\n",
        "                      \"Model Size\": str(model_size) + \" bytes\",\n",
        "                      \"Inference Time\": str(executionTime) + \" sec\"\n",
        "                    }\n",
        "  \n",
        "  evulation_df = pd.DataFrame.from_dict(evulation_dict, orient='index').reset_index()\n",
        "\n",
        "\n",
        "  return test_acc, model_size, executionTime, evulation_df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# research paper evaluation function\n",
        "def evaluate_research_paper_with_model_path(model_path):\n",
        "  # model_path = \"/content/models/solnet.hdf5\"\n",
        "  solnet = load_model(model_path, compile=False)\n",
        "  history = solnet.history()\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.title('acc loss vs epoch')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['loss', 'acc'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "def evaluate_research_paper_with_model(model):\n",
        "  history = model.history()\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.title('acc loss vs epoch')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['loss', 'acc'], loc='upper left')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load base model and Evaluate\n"
      ],
      "metadata": {
        "id": "LSh8r6pSvbTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# final_model_path = '/content/drive/MyDrive/Solar_panel_dust_detection/final_base_model/solnetOriginal_final_base_model.hdf5'\n",
        "final_model_path = '/content/drive/MyDrive/Solar_panel_dust_detection/final_base_model/final_base_model.h5'\n",
        "final_model = tf.keras.models.load_model(final_model_path)"
      ],
      "metadata": {
        "id": "PxxCx3C9vetW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "#location = 'dataset/'\n",
        "location = \"/content/drive/MyDrive/Solar_panel_dust_detection/dataset_1\"\n",
        "label_mode = 'binary'\n",
        "seed = 10 #changed for each fold made manually\n",
        "\n",
        "class_names = ['clean', 'dirty']\n",
        "in_size = [227, 227, 3]\n",
        "\n",
        "tr_dataset = image_dataset_from_directory(directory=location, label_mode= label_mode, class_names=class_names,\n",
        "                                          seed=seed, labels='inferred', image_size=in_size[:-1], \n",
        "                                          subset = 'training', batch_size=batch_size, validation_split=.2)\n",
        "\n",
        "val_dataset = image_dataset_from_directory(directory=location, label_mode= label_mode, class_names=class_names,\n",
        "                                          seed=seed, labels='inferred', image_size=in_size[:-1],\n",
        "                                          subset = 'validation', batch_size=batch_size, validation_split=.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADxrshiBxYPD",
        "outputId": "cf4e946a-e3b8-425b-96a0-b5a6ca3734b9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1440 files belonging to 2 classes.\n",
            "Using 1152 files for training.\n",
            "Found 1440 files belonging to 2 classes.\n",
            "Using 288 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc, model_size, executionTime, evulation_df = evaluate_model_without_saving_stats(final_model, final_model_path, \"#0\", val_dataset)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV4ptHfowaOW",
        "outputId": "fcde1950-73ff-4561-8f0f-1c27a27088ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 26s 39ms/step\n",
            "\n",
            "Model Accuracy: 96.18055820465088 %\n",
            "Model Size: 648760230.00 bytes\n",
            "Inference Time is:  2.910879029168023 s\n",
            "0.9618055820465088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evulation_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "4fTy3GU83zDO",
        "outputId": "fb80aa52-fc46-4c68-f474-197d47402f31"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               index                      0\n",
              "0    Evaluation type             Evualation\n",
              "1  Model Information                     #0\n",
              "2           Accuracy    96.18055820465088 %\n",
              "3               Loss    11.30877360701561 %\n",
              "4         Model Size        648760230 bytes\n",
              "5     Inference Time  2.910879029168023 sec"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff1ecc1f-71e7-424b-8a7f-5c08997dca80\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Evaluation type</td>\n",
              "      <td>Evualation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Model Information</td>\n",
              "      <td>#0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Accuracy</td>\n",
              "      <td>96.18055820465088 %</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Loss</td>\n",
              "      <td>11.30877360701561 %</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Model Size</td>\n",
              "      <td>648760230 bytes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Inference Time</td>\n",
              "      <td>2.910879029168023 sec</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff1ecc1f-71e7-424b-8a7f-5c08997dca80')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff1ecc1f-71e7-424b-8a7f-5c08997dca80 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff1ecc1f-71e7-424b-8a7f-5c08997dca80');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compression"
      ],
      "metadata": {
        "id": "hKWpWBoJ7RE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-shot pruning"
      ],
      "metadata": {
        "id": "zmTJKsl3k1eM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l2atUG2Pk3yx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Iterative pruning"
      ],
      "metadata": {
        "id": "O_U5jD0hkyGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def iterative_pruning(model, initial_sparsity, final_sparsity, begin_step, end_step, train_images, train_labels, epochs):\n",
        "  prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "  # Define model for pruning.\n",
        "  pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=initial_sparsity,\n",
        "        final_sparsity=final_sparsity, begin_step=begin_step, end_step=end_step, frequency=100)\n",
        "  }\n",
        "\n",
        "  pruned_model = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "  # `prune_low_magnitude` requires a recompile.\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "  pruned_model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  callbacks = [\n",
        "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  ]\n",
        "\n",
        "  pruned_model.fit(train_images, train_labels, epochs=epochs, validation_split=0.1,\n",
        "                    callbacks=callbacks)\n",
        "\n",
        "  # Strip pruning wrappers\n",
        "  stripped_pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
        "\n",
        "  return pruned_model, stripped_pruned_model\n",
        "\n",
        "\n",
        "def iterative_pruning2(model, initial_sparsity, final_sparsity, begin_step, end_step, tdata_loader,vdata_loader, epochs):\n",
        "  prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "  # Define model for pruning.\n",
        "  pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=initial_sparsity,\n",
        "          final_sparsity=final_sparsity, begin_step=begin_step, end_step=end_step, frequency=100)\n",
        "  }\n",
        "\n",
        "  pruned_model = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "  # `prune_low_magnitude` requires a recompile.\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "  pruned_model.compile(optimizer=Adam(.0001, .8, .9),\n",
        "      loss=binary_crossentropy,\n",
        "      metrics=['accuracy'])\n",
        "\n",
        "  callbacks = [\n",
        "      tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  ]\n",
        "\n",
        "  pruned_model.fit(tdata_loader, epochs=epochs, validation_data=vdata_loader, callbacks=callbacks)\n",
        "\n",
        "  # Strip pruning wrappers\n",
        "  stripped_pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
        "\n",
        "  return pruned_model, stripped_pruned_model"
      ],
      "metadata": {
        "id": "EUHJdVqN7Ucd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# frquency = 100\n",
        "# target sparsity = 50%\n",
        "# sparisty for each pruning tep = 50%/100 = 0.05%\n",
        "# Total Number of Training Samples = 1440\n",
        "# batch size = 32\n",
        "# epochs = 10\n",
        "\n",
        "# possible start and end for the iterative pruning schedule\n",
        "# Number of learning steps = (1440/32)*3 = 135 (15, 120)\n",
        "# Number of learning steps = (1440/32)*4 = 180 (, )\n",
        "# Number of learning steps = (1440/32)*5 = 225 (, )\n",
        "# Number of learning steps = (1440/32)*6 = 270 (, )\n",
        "\n",
        "# Number of learning steps = (1440/32)*10 = 450 (45, 400)\n",
        "# Number of learning steps = (1440/32)*20 = 900 (90, 800)\n",
        "# Number of learning steps = (1440/32)*25 = 1125 (110, 1010)\n",
        "# Number of learning steps = (1440/32)*30 = 1350 (135, 1200)\n",
        "# Number of learning steps = (1440/32)*35 = 1575 (150, 1400)\n",
        "\n",
        "\n",
        "# Number of learning steps = (1440/32)*30 = 1350 (135, 1200)\n",
        "\n",
        "# iterative_pruning(\n",
        "                  #     model, \n",
        "                  #     initial_sparsity = 0, \n",
        "                  #     final_sparsity   = 0.9, \n",
        "                  #     begin_step       = 0, 600  (~10% of 5625) # pruning early on the pruning schedule to get optimal model size\n",
        "                  #     end_step         = ?, 4500 (~80% of 5625) # pruning only till 80% so that model can still have enough leanring steps to learn and build networks for the data\n",
        "                  #     train_images, \n",
        "                  #     train_labels, \n",
        "                  #     epochs           = 3, no change ? since the Number of Steps per Epoch = (Total Number of Training Samples = ?) / (Batch Size = ?) \n",
        "                  # )\n",
        "\n",
        "\n",
        "\n",
        "# pruned_model_saprsity_50, stripped_pruned_model_saprsity_50 = iterative_pruning2(final_model, 0, 0.5, 45, 400, tr_dataset, val_dataset, 10)\n",
        "# pruned_model_saprsity_50, stripped_pruned_model_saprsity_50 = iterative_pruning2(final_model, 0, 0.5, 90, 800, tr_dataset, val_dataset, 20)\n",
        "# pruned_model_saprsity_50, stripped_pruned_model_saprsity_50 = iterative_pruning2(final_model, 0, 0.5, 110, 1010, tr_dataset, val_dataset, 25)\n",
        "# pruned_model_saprsity_50, stripped_pruned_model_saprsity_50 = iterative_pruning2(final_model, 0, 0.5, 135, 1200, tr_dataset, val_dataset, 30)\n",
        "pruned_model_saprsity_50, stripped_pruned_model_saprsity_50 = iterative_pruning2(final_model, 0, 0.5, 150, 1400, tr_dataset, val_dataset, 35)\n",
        "\n",
        "\n",
        "\n",
        "# pruned_model_saprsity_50, stripped_pruned_model_saprsity_50 = iterative_pruning(final_model, 0, 0.5, 15, 120, x_train_images, x_train_labels, 3)\n",
        "# pruned_model_saprsity_50, stripped_pruned_model_saprsity_50 = iterative_pruning(final_model, 0, 0.9, 45, 400, x_train_images, x_train_labels, 10)\n",
        "# pruned_model_saprsity_50, stripped_pruned_model_saprsity_50 = iterative_pruning(final_model, 0, 0.5, 135, 1200, x_train_images, x_train_labels, 30)"
      ],
      "metadata": {
        "id": "HuM0MQw98bOn",
        "outputId": "30b89b5c-1de9-4bc0-908b-5f1f61768c90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "36/36 [==============================] - 134s 3s/step - loss: 0.1181 - accuracy: 0.9844 - val_loss: 2.6201 - val_accuracy: 0.7951\n",
            "Epoch 2/35\n",
            "36/36 [==============================] - 127s 3s/step - loss: 0.0974 - accuracy: 0.9870 - val_loss: 0.6264 - val_accuracy: 0.9236\n",
            "Epoch 3/35\n",
            "36/36 [==============================] - 126s 3s/step - loss: 0.1015 - accuracy: 0.9844 - val_loss: 10.9988 - val_accuracy: 0.6424\n",
            "Epoch 4/35\n",
            "36/36 [==============================] - 125s 3s/step - loss: 0.1026 - accuracy: 0.9826 - val_loss: 11.2208 - val_accuracy: 0.6250\n",
            "Epoch 5/35\n",
            "36/36 [==============================] - 125s 3s/step - loss: 0.1560 - accuracy: 0.9844 - val_loss: 2.8921 - val_accuracy: 0.7917\n",
            "Epoch 6/35\n",
            "36/36 [==============================] - 142s 3s/step - loss: 0.1166 - accuracy: 0.9844 - val_loss: 10.2796 - val_accuracy: 0.6389\n",
            "Epoch 7/35\n",
            "36/36 [==============================] - 140s 3s/step - loss: 0.0549 - accuracy: 0.9878 - val_loss: 5.0843 - val_accuracy: 0.7049\n",
            "Epoch 8/35\n",
            "36/36 [==============================] - 126s 3s/step - loss: 0.0562 - accuracy: 0.9896 - val_loss: 5.2169 - val_accuracy: 0.6979\n",
            "Epoch 9/35\n",
            "36/36 [==============================] - 123s 3s/step - loss: 0.0852 - accuracy: 0.9878 - val_loss: 1.2383 - val_accuracy: 0.8715\n",
            "Epoch 10/35\n",
            "36/36 [==============================] - 122s 3s/step - loss: 0.1076 - accuracy: 0.9870 - val_loss: 0.8298 - val_accuracy: 0.8958\n",
            "Epoch 11/35\n",
            "36/36 [==============================] - 127s 3s/step - loss: 0.0492 - accuracy: 0.9948 - val_loss: 0.8598 - val_accuracy: 0.9062\n",
            "Epoch 12/35\n",
            "36/36 [==============================] - 123s 3s/step - loss: 0.0476 - accuracy: 0.9896 - val_loss: 1.9931 - val_accuracy: 0.8785\n",
            "Epoch 13/35\n",
            "36/36 [==============================] - 142s 3s/step - loss: 0.0283 - accuracy: 0.9931 - val_loss: 1.5132 - val_accuracy: 0.8750\n",
            "Epoch 14/35\n",
            "36/36 [==============================] - 125s 3s/step - loss: 0.0519 - accuracy: 0.9913 - val_loss: 0.7274 - val_accuracy: 0.9271\n",
            "Epoch 15/35\n",
            "36/36 [==============================] - 123s 3s/step - loss: 0.0381 - accuracy: 0.9965 - val_loss: 0.7170 - val_accuracy: 0.9340\n",
            "Epoch 16/35\n",
            "36/36 [==============================] - 142s 3s/step - loss: 0.0230 - accuracy: 0.9957 - val_loss: 0.5392 - val_accuracy: 0.9514\n",
            "Epoch 17/35\n",
            "36/36 [==============================] - 124s 3s/step - loss: 0.0690 - accuracy: 0.9948 - val_loss: 7.6846 - val_accuracy: 0.6250\n",
            "Epoch 18/35\n",
            "36/36 [==============================] - 124s 3s/step - loss: 0.0443 - accuracy: 0.9922 - val_loss: 0.6589 - val_accuracy: 0.9479\n",
            "Epoch 19/35\n",
            "36/36 [==============================] - 126s 3s/step - loss: 0.0618 - accuracy: 0.9931 - val_loss: 4.8659 - val_accuracy: 0.7257\n",
            "Epoch 20/35\n",
            "36/36 [==============================] - 143s 3s/step - loss: 0.0388 - accuracy: 0.9974 - val_loss: 0.4603 - val_accuracy: 0.9583\n",
            "Epoch 21/35\n",
            "36/36 [==============================] - 127s 3s/step - loss: 1.0206e-04 - accuracy: 1.0000 - val_loss: 0.4594 - val_accuracy: 0.9653\n",
            "Epoch 22/35\n",
            "36/36 [==============================] - 143s 3s/step - loss: 0.0146 - accuracy: 0.9983 - val_loss: 0.7612 - val_accuracy: 0.9479\n",
            "Epoch 23/35\n",
            "36/36 [==============================] - 127s 3s/step - loss: 5.1560e-04 - accuracy: 1.0000 - val_loss: 0.4284 - val_accuracy: 0.9583\n",
            "Epoch 24/35\n",
            "36/36 [==============================] - 127s 3s/step - loss: 0.0412 - accuracy: 0.9948 - val_loss: 0.5916 - val_accuracy: 0.9583\n",
            "Epoch 25/35\n",
            "36/36 [==============================] - 127s 3s/step - loss: 0.0162 - accuracy: 0.9974 - val_loss: 0.7736 - val_accuracy: 0.9340\n",
            "Epoch 26/35\n",
            "36/36 [==============================] - 127s 3s/step - loss: 0.0084 - accuracy: 0.9991 - val_loss: 1.3663 - val_accuracy: 0.8819\n",
            "Epoch 27/35\n",
            "36/36 [==============================] - 127s 3s/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.7133 - val_accuracy: 0.9549\n",
            "Epoch 28/35\n",
            "36/36 [==============================] - 126s 3s/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 1.4433 - val_accuracy: 0.8889\n",
            "Epoch 29/35\n",
            "36/36 [==============================] - 143s 3s/step - loss: 0.0133 - accuracy: 0.9965 - val_loss: 0.7663 - val_accuracy: 0.9653\n",
            "Epoch 30/35\n",
            "36/36 [==============================] - 143s 3s/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.7864 - val_accuracy: 0.9549\n",
            "Epoch 31/35\n",
            "36/36 [==============================] - 126s 3s/step - loss: 0.0172 - accuracy: 0.9957 - val_loss: 1.8036 - val_accuracy: 0.8299\n",
            "Epoch 32/35\n",
            "36/36 [==============================] - 126s 3s/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.7827 - val_accuracy: 0.9271\n",
            "Epoch 33/35\n",
            "36/36 [==============================] - 125s 3s/step - loss: 0.0057 - accuracy: 0.9974 - val_loss: 1.2116 - val_accuracy: 0.9062\n",
            "Epoch 34/35\n",
            "36/36 [==============================] - 124s 3s/step - loss: 0.0456 - accuracy: 0.9957 - val_loss: 0.4748 - val_accuracy: 0.9653\n",
            "Epoch 35/35\n",
            "36/36 [==============================] - 126s 3s/step - loss: 0.0082 - accuracy: 0.9991 - val_loss: 0.5738 - val_accuracy: 0.9722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stripped_pruned_model_saprsity_50.save('stripped_pruned_model_saprsity_50.h5')"
      ],
      "metadata": {
        "id": "g3FlKdYN93_C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b84db8f3-13f0-4e3e-8bbb-b983d937bf86"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_model_weights_sparsity(model):\n",
        "\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.layers.Wrapper):\n",
        "            weights = layer.trainable_weights\n",
        "        else:\n",
        "            weights = layer.weights\n",
        "        for weight in weights:\n",
        "            if \"kernel\" not in weight.name or \"centroid\" in weight.name:\n",
        "                continue\n",
        "            weight_size = weight.numpy().size\n",
        "            zero_num = np.count_nonzero(weight == 0)\n",
        "            print(\n",
        "                f\"{weight.name}: {zero_num/weight_size:.2%} sparsity \",\n",
        "                f\"({zero_num}/{weight_size})\",\n",
        "            )\n",
        "\n",
        "\n",
        "print_model_weights_sparsity(pruned_model_saprsity_50)"
      ],
      "metadata": {
        "id": "EIs-x_kdLIBa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2792c19-5671-4710-ecfa-420db486827a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv2d_10/kernel:0: 49.91% sparsity  (17394/34848)\n",
            "conv2d_11/kernel:0: 49.91% sparsity  (306669/614400)\n",
            "conv2d_12/kernel:0: 49.91% sparsity  (441604/884736)\n",
            "conv2d_13/kernel:0: 49.91% sparsity  (662405/1327104)\n",
            "conv2d_14/kernel:0: 49.91% sparsity  (441604/884736)\n",
            "dense_6/kernel:0: 49.91% sparsity  (18841752/37748736)\n",
            "dense_7/kernel:0: 49.91% sparsity  (8374112/16777216)\n",
            "dense_8/kernel:0: 49.90% sparsity  (2044/4096)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_pruned_50, test_acc_pruned_50 = pruned_model_saprsity_50.evaluate(val_dataset, verbose=0)"
      ],
      "metadata": {
        "id": "ruil9B3BLeQw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "startTime = time.time()\n",
        "prediction = pruned_model_saprsity_50.predict(val_dataset)\n",
        "executionTimePruned50 = (time.time() - startTime)/len(val_dataset)"
      ],
      "metadata": {
        "id": "by95PgEOL90Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d17bd9b9-fbd6-4573-f112-734904d13c42"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 25s 50ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_model_size = get_gzipped_model_size('stripped_pruned_model_saprsity_50.h5')"
      ],
      "metadata": {
        "id": "x9tFiIELMDyK"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\nPruned Model Accuracy:', test_acc_pruned_50*100, '%')\n",
        "print(\"Pruned Model Size: %.2f bytes\" % (pruned_model_size))\n",
        "print(\"Pruned Inference Time is\", executionTimePruned50, \"s\")"
      ],
      "metadata": {
        "id": "v7OA78GSZrE-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4f72413-9f06-4cc7-eb78-085383bf92c0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pruned Model Accuracy: 97.22222089767456 %\n",
            "Pruned Model Size: 129392360.00 bytes\n",
            "Pruned Inference Time is 4.59256895383199 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_test_acc, pruned_model_size, pruned_executionTime, pruned_evulation_df = evaluate_model_without_saving_stats(pruned_model_saprsity_50, 'stripped_pruned_model_saprsity_50.h5', \"#1\", val_dataset)\n",
        "print(pruned_test_acc)"
      ],
      "metadata": {
        "id": "qOB46ZJl45Gn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d7c932f-94e0-4a6b-e39f-1bc4a53c0803"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 25s 39ms/step\n",
            "\n",
            "Model Accuracy: 97.22222089767456 %\n",
            "Model Size: 129392360.00 bytes\n",
            "Inference Time is:  2.779461224873861 s\n",
            "0.9722222089767456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_evulation_df"
      ],
      "metadata": {
        "id": "69S4hOmr5K9C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "9d2c1ec3-0180-4b64-b441-d7893e4a76c4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               index                      0\n",
              "0    Evaluation type             Evualation\n",
              "1  Model Information                     #1\n",
              "2           Accuracy    97.22222089767456 %\n",
              "3               Loss    57.37696290016174 %\n",
              "4         Model Size        129392360 bytes\n",
              "5     Inference Time  2.779461224873861 sec"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-577aa37b-80bc-44ce-b4bb-f6404eeaac00\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Evaluation type</td>\n",
              "      <td>Evualation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Model Information</td>\n",
              "      <td>#1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Accuracy</td>\n",
              "      <td>97.22222089767456 %</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Loss</td>\n",
              "      <td>57.37696290016174 %</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Model Size</td>\n",
              "      <td>129392360 bytes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Inference Time</td>\n",
              "      <td>2.779461224873861 sec</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-577aa37b-80bc-44ce-b4bb-f6404eeaac00')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-577aa37b-80bc-44ce-b4bb-f6404eeaac00 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-577aa37b-80bc-44ce-b4bb-f6404eeaac00');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evulation_df"
      ],
      "metadata": {
        "id": "gXToE5LuMQUK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "2bb6395b-0865-428d-ea1c-8e5f1b404943"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               index                      0\n",
              "0    Evaluation type             Evualation\n",
              "1  Model Information                     #0\n",
              "2           Accuracy    96.18055820465088 %\n",
              "3               Loss    11.30877360701561 %\n",
              "4         Model Size        648760230 bytes\n",
              "5     Inference Time  2.910879029168023 sec"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eff9df84-5035-466b-819b-3b32ac31a17a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Evaluation type</td>\n",
              "      <td>Evualation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Model Information</td>\n",
              "      <td>#0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Accuracy</td>\n",
              "      <td>96.18055820465088 %</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Loss</td>\n",
              "      <td>11.30877360701561 %</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Model Size</td>\n",
              "      <td>648760230 bytes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Inference Time</td>\n",
              "      <td>2.910879029168023 sec</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eff9df84-5035-466b-819b-3b32ac31a17a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eff9df84-5035-466b-819b-3b32ac31a17a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eff9df84-5035-466b-819b-3b32ac31a17a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_model_saprsity_50.save('/content/drive/MyDrive/Solar_panel_dust_detection/final_base_model/pruned_model_saprsity_50.h5')\n",
        "stripped_pruned_model_saprsity_50.save('/content/drive/MyDrive/Solar_panel_dust_detection/final_base_model/stripped_pruned_model_saprsity_50.h5')"
      ],
      "metadata": {
        "id": "evvy6LXH64Sq",
        "outputId": "0b29e4d3-e4f0-4c59-9c42-63efcac2819e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-0323d211278f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpruned_model_saprsity_50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Solar_panel_dust_detection/final_base_model/pruned_model_saprsity_50.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstripped_pruned_model_saprsity_50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Solar_panel_dust_detection/final_base_model/stripped_pruned_model_saprsity_50.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, save_format, **kwargs)\u001b[0m\n\u001b[1;32m   2824\u001b[0m         \u001b[0mNote\u001b[0m \u001b[0mthat\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0man\u001b[0m \u001b[0malias\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2825\u001b[0m         \"\"\"\n\u001b[0;32m-> 2826\u001b[0;31m         saving_api.save_model(\n\u001b[0m\u001b[1;32m   2827\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/saving/saving_api.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, save_format, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# Legacy case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         return legacy_sm_saving_lib.save_model(\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/saving/legacy/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;34m'setting save_format=\"tf\") or using `save_weights`.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             )\n\u001b[0;32m--> 160\u001b[0;31m         hdf5_format.save_model_to_hdf5(\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/saving/legacy/hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    565\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 567\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5g.pyx\u001b[0m in \u001b[0;36mh5py.h5g.GroupID.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5g.pyx\u001b[0m in \u001b[0;36mh5py.h5g.GroupID.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_model_saprsity_50.save('pruned_model_saprsity_50.h5')\n",
        "stripped_pruned_model_saprsity_50.save('stripped_pruned_model_saprsity_50.h5')"
      ],
      "metadata": {
        "id": "PDc_Y3xs3no6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantization"
      ],
      "metadata": {
        "id": "TFNqDAak5AFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_to_quantize)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "fp16_quantized_tflite_model = converter.convert()\n",
        "\n",
        "with open('fp16_quantized_tflite_model.tflite', 'wb') as f:\n",
        "  f.write(fp16_quantized_tflite_model)\n",
        "interpreter_fp16_quant = tf.lite.Interpreter(model_path=str('fp16_quantized_tflite_model.tflite'))\n",
        "interpreter_fp16_quant.allocate_tensors()\n",
        "\n",
        "evaluate_model(interpreter_fp16_quant, 'fp16_quantized_tflite_model.tflite')"
      ],
      "metadata": {
        "id": "6b44dStg5B4y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}