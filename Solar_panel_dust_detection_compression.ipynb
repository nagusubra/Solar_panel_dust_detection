{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nagusubra/Solar_panel_dust_detection/blob/main/Solar_panel_dust_detection_compression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQAMdUOp9lRn"
      },
      "source": [
        "#Install libraries and modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLxJiY6u9Zh0",
        "outputId": "ec95ad84-df24-4074-b964-355eb650b260"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/238.9 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.9/dist-packages (3.0.10)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.9/dist-packages (from openpyxl) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.0.9-py3-none-any.whl (152 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 KB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.0.9\n"
          ]
        }
      ],
      "source": [
        "!pip install -q tensorflow-model-optimization\n",
        "!pip install openpyxl\n",
        "!pip install xlsxwriter\n",
        "\n",
        "import xlsxwriter\n",
        "import openpyxl\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.drawing.image import Image\n",
        "\n",
        "import tempfile\n",
        "from tensorflow import keras\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qeqtoyTCppFF"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, Dropout\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "import os\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WVnbwh-9x2l",
        "outputId": "2911d1e8-0a04-4cc6-c6a4-c4b4e5f1f791"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mounting google drive (if you are using Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjpFrB77S6QU"
      },
      "source": [
        "# Evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oB55zL05S_Oe"
      },
      "outputs": [],
      "source": [
        "# Evaluate Model Size\n",
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "  return os.path.getsize(zipped_file)\n",
        "\n",
        "\n",
        "def evaluate_model(model_path, model_info, val_dataset):\n",
        "\n",
        "  # Evaluate test accuracy and test loss\n",
        "  model = tf.keras.models.load_model(model_path)\n",
        "  test_loss, test_acc = model.evaluate(val_dataset, verbose=0)\n",
        "\n",
        "  # Evaluate Model Size\n",
        "  model_size = get_gzipped_model_size(model_path)\n",
        "\n",
        "  # Evaluate Inference Time\n",
        "  startTime = time.time()\n",
        "  prediction = model.predict(val_dataset)\n",
        "  executionTime = (time.time() - startTime)/len(val_dataset)\n",
        "\n",
        "  # Print\n",
        "  print('\\nModel Accuracy:', test_acc*100, '%')\n",
        "  print(\"Model Size: %.2f bytes\" % (model_size))\n",
        "  print(\"Inference Time is: \", executionTime, \"s\")\n",
        "\n",
        "  # Build Evalution dataframe\n",
        "  evulation_dict = {\n",
        "                      \"Evaluation type\": \"Evualation\",\n",
        "                      \"Model Information\": model_info,\n",
        "                      \"Accuracy\": str(test_acc*100) + \" %\",\n",
        "                      \"Loss\": str(test_loss*100) + \" %\",\n",
        "                      \"Model Size\": str(model_size) + \" bytes\",\n",
        "                      \"Inference Time\": str(executionTime) + \" sec\"\n",
        "                    }\n",
        "  \n",
        "  evulation_df = pd.DataFrame.from_dict(evulation_dict, orient='index').reset_index()\n",
        "\n",
        "\n",
        "  return test_acc, model_size, executionTime, evulation_df\n",
        "\n",
        "\n",
        "def evaluate_model_without_saving_stats(model, model_path, model_info, val_dataset):\n",
        "\n",
        "  # Evaluate test accuracy and test loss\n",
        "  # model = tf.keras.models.load_model(model_path)\n",
        "  test_loss, test_acc = model.evaluate(val_dataset, verbose=0)\n",
        "\n",
        "  # Evaluate Model Size\n",
        "  model_size = get_gzipped_model_size(model_path)\n",
        "\n",
        "  # Evaluate Inference Time\n",
        "  startTime = time.time()\n",
        "  prediction = model.predict(val_dataset)\n",
        "  executionTime = (time.time() - startTime)/len(val_dataset)\n",
        "\n",
        "  # Print\n",
        "  print('\\nModel Accuracy:', test_acc*100, '%')\n",
        "  print(\"Model Size: %.2f bytes\" % (model_size))\n",
        "  print(\"Inference Time is: \", executionTime, \"s\")\n",
        "\n",
        "  # Build Evalution dataframe\n",
        "  evulation_dict = {\n",
        "                      \"Evaluation type\": \"Evualation\",\n",
        "                      \"Model Information\": model_info,\n",
        "                      \"Accuracy\": str(test_acc*100) + \" %\",\n",
        "                      \"Loss\": str(test_loss*100) + \" %\",\n",
        "                      \"Model Size\": str(model_size) + \" bytes\",\n",
        "                      \"Inference Time\": str(executionTime) + \" sec\"\n",
        "                    }\n",
        "  \n",
        "  evulation_df = pd.DataFrame.from_dict(evulation_dict, orient='index').reset_index()\n",
        "\n",
        "\n",
        "  return test_acc, model_size, executionTime, evulation_df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# research paper evaluation function\n",
        "def evaluate_research_paper_with_model_path(model_path):\n",
        "  # model_path = \"/content/models/solnet.hdf5\"\n",
        "  solnet = load_model(model_path, compile=False)\n",
        "  history = solnet.history()\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.title('acc loss vs epoch')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['loss', 'acc'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "def evaluate_research_paper_with_model(model):\n",
        "  history = model.history()\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.title('acc loss vs epoch')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['loss', 'acc'], loc='upper left')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load base model and Evaluate\n"
      ],
      "metadata": {
        "id": "LSh8r6pSvbTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model_path = '/content/drive/MyDrive/Solar_panel_dust_detection/final_base_model/solnetOriginal_final_base_model.hdf5'\n",
        "final_model = tf.keras.models.load_model(final_model_path)"
      ],
      "metadata": {
        "id": "PxxCx3C9vetW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "#location = 'dataset/'\n",
        "location = \"/content/drive/MyDrive/Solar_panel_dust_detection/dataset_1\"\n",
        "label_mode = 'binary'\n",
        "seed = 10 #changed for each fold made manually\n",
        "\n",
        "class_names = ['clean', 'dirty']\n",
        "in_size = [227, 227, 3]\n",
        "\n",
        "tr_dataset = image_dataset_from_directory(directory=location, label_mode= label_mode, class_names=class_names,\n",
        "                                          seed=seed, labels='inferred', image_size=in_size[:-1], \n",
        "                                          subset = 'training', batch_size=batch_size, validation_split=.2)\n",
        "\n",
        "val_dataset = image_dataset_from_directory(directory=location, label_mode= label_mode, class_names=class_names,\n",
        "                                          seed=seed, labels='inferred', image_size=in_size[:-1],\n",
        "                                          subset = 'validation', batch_size=batch_size, validation_split=.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADxrshiBxYPD",
        "outputId": "9388f295-1e8a-49d6-f490-39b4a64da3a6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1440 files belonging to 2 classes.\n",
            "Using 1152 files for training.\n",
            "Found 1440 files belonging to 2 classes.\n",
            "Using 288 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc, model_size, executionTime, evulation_df = evaluate_model_without_saving_stats(final_model, final_model_path, \"#0\", val_dataset)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV4ptHfowaOW",
        "outputId": "e5c30ae6-a828-4cdd-ae6c-c69593b85a4e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 24s 33ms/step\n",
            "\n",
            "Model Accuracy: 72.56944179534912 %\n",
            "Model Size: 659509171.00 bytes\n",
            "Inference Time is:  4.570444742838542 s\n",
            "0.7256944179534912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evulation_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "4fTy3GU83zDO",
        "outputId": "b45926fe-fd62-4743-f90b-7ce12be87492"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               index                      0\n",
              "0    Evaluation type             Evualation\n",
              "1  Model Information                     #0\n",
              "2           Accuracy    72.56944179534912 %\n",
              "3               Loss   261.79609298706055 %\n",
              "4         Model Size        659509171 bytes\n",
              "5     Inference Time  4.570444742838542 sec"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d806a715-4f85-4e23-b641-98c6ff0978b5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Evaluation type</td>\n",
              "      <td>Evualation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Model Information</td>\n",
              "      <td>#0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Accuracy</td>\n",
              "      <td>72.56944179534912 %</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Loss</td>\n",
              "      <td>261.79609298706055 %</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Model Size</td>\n",
              "      <td>659509171 bytes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Inference Time</td>\n",
              "      <td>4.570444742838542 sec</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d806a715-4f85-4e23-b641-98c6ff0978b5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d806a715-4f85-4e23-b641-98c6ff0978b5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d806a715-4f85-4e23-b641-98c6ff0978b5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compression"
      ],
      "metadata": {
        "id": "hKWpWBoJ7RE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def iterative_pruning(model, initial_sparsity, final_sparsity, begin_step, end_step, train_images, train_labels, epochs):\n",
        "  prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "  # Define model for pruning.\n",
        "  pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=initial_sparsity,\n",
        "        final_sparsity=final_sparsity, begin_step=begin_step, end_step=end_step, frequency=100)\n",
        "  }\n",
        "\n",
        "  pruned_model = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "  # `prune_low_magnitude` requires a recompile.\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "  pruned_model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  callbacks = [\n",
        "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  ]\n",
        "\n",
        "  pruned_model.fit(train_images, train_labels, epochs=epochs, validation_split=0.1,\n",
        "                    callbacks=callbacks)\n",
        "\n",
        "  # Strip pruning wrappers\n",
        "  stripped_pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
        "\n",
        "  return pruned_model, stripped_pruned_model"
      ],
      "metadata": {
        "id": "EUHJdVqN7Ucd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(tr_dataset)"
      ],
      "metadata": {
        "id": "90OgDhUsD742",
        "outputId": "9bac092f-207f-4325-f5e1-7aaed5164a12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.batch_op._BatchDataset"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "x_train = None\n",
        "x_train_labels = None\n",
        "\n",
        "for image, label in tfds.as_numpy(tr_dataset):\n",
        "  # print(type(image), type(label), label, len(label))\n",
        "  x_train = image\n",
        "  x_train_labels = label\n",
        "  \n",
        "  print(type(x_train))\n",
        "  print(len(x_train))\n",
        "  print(x_train.ndim)\n",
        "  print(x_train.shape)\n",
        "\n",
        "  \n",
        "  print('------')"
      ],
      "metadata": {
        "id": "mpu7bcg_H_Ya",
        "outputId": "b30efdf6-bd48-425e-ceb0-0f4b46488945",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n",
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n",
            "------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = None\n",
        "\n",
        "for image, label in tfds.as_numpy(val_dataset):\n",
        "  print(type(image), type(label), label, len(label))\n",
        "  x_test = image\n",
        "  x_test_labels = label\n",
        "  print('------')"
      ],
      "metadata": {
        "id": "WVk5Q2JrLnxW",
        "outputId": "e47c67e1-2e09-4f10-b59e-b1f343948d64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> [[1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] 32\n",
            "------\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> [[1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]] 32\n",
            "------\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> [[1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]] 32\n",
            "------\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> [[1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]] 32\n",
            "------\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> [[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]] 32\n",
            "------\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> [[0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]] 32\n",
            "------\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> [[1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]] 32\n",
            "------\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> [[0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]] 32\n",
            "------\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> [[0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]] 32\n",
            "------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(x_train))\n",
        "print(len(x_train))\n",
        "print(x_train.ndim)\n",
        "print(x_train.shape)\n"
      ],
      "metadata": {
        "id": "xRCaI-WgIIRV",
        "outputId": "818e532f-1f87-482c-8a27-1401fda029ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_images = np.empty(0)\n",
        "x_train_labels = np.empty(0)\n",
        "\n",
        "for image, label in tfds.as_numpy(tr_dataset):\n",
        "  # print(type(image), type(label), label, len(label))\n",
        "  x_train_images = np.append(x_train_images, image)\n",
        "  x_train_labels = np.append(x_train_labels, label)\n",
        "  # print('------')\n"
      ],
      "metadata": {
        "id": "WZvyytWVNcyM"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(type(x_train_images))\n",
        "print(len(x_train_images))\n",
        "print(x_train_images.ndim)\n",
        "print(x_train_images.shape)"
      ],
      "metadata": {
        "id": "I_KuxEZCPvjd",
        "outputId": "51e0a451-e34e-4511-aa46-6d1eeb3e2fac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "178084224\n",
            "1\n",
            "(178084224,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(x_train))\n",
        "print(len(x_train))\n",
        "print(x_train.ndim)\n",
        "print(x_train.shape)\n"
      ],
      "metadata": {
        "id": "feLSN4laNkCs",
        "outputId": "8f0759a4-9d3d-44d6-b9ce-765c22fa446a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "32\n",
            "4\n",
            "(32, 227, 227, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "id": "GFGSTHYaIsnY",
        "outputId": "576c03bd-5d10-488b-dbb7-958b129a3845",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 89.32104   , 103.3761    , 126.06112   ],\n",
              "         [ 98.20719   , 105.15212   , 133.98691   ],\n",
              "         [ 95.99023   , 102.99023   , 131.99023   ],\n",
              "         ...,\n",
              "         [102.10312   ,  95.10312   ,  76.10312   ],\n",
              "         [133.23564   , 124.29034   , 115.18096   ],\n",
              "         [126.924995  , 119.924995  , 100.924995  ]],\n",
              "\n",
              "        [[ 95.        , 102.31498   , 127.37004   ],\n",
              "         [100.        , 107.        , 135.8348    ],\n",
              "         [ 95.        , 102.        , 131.        ],\n",
              "         ...,\n",
              "         [186.81335   , 179.81335   , 160.81335   ],\n",
              "         [157.67924   , 150.67924   , 131.67924   ],\n",
              "         [114.85003   , 107.85003   ,  88.85003   ]],\n",
              "\n",
              "        [[100.        , 107.31498   , 132.37004   ],\n",
              "         [ 98.53084   , 105.53084   , 134.36563   ],\n",
              "         [101.14978   , 108.14978   , 137.14978   ],\n",
              "         ...,\n",
              "         [115.76187   , 108.76187   ,  89.76187   ],\n",
              "         [145.74023   , 138.74023   , 119.74023   ],\n",
              "         [114.64123   , 107.64123   ,  88.64123   ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[168.00552   , 177.00552   , 194.00552   ],\n",
              "         [ 99.        , 107.94493   , 125.05507   ],\n",
              "         [ 94.57489   , 103.57489   , 120.57489   ],\n",
              "         ...,\n",
              "         [180.0016    , 152.0016    , 128.0016    ],\n",
              "         [187.0648    , 169.79137   , 153.90074   ],\n",
              "         [204.33861   , 176.33861   , 152.33861   ]],\n",
              "\n",
              "        [[106.37004   , 115.37004   , 132.37004   ],\n",
              "         [102.66797   , 111.6129    , 128.72304   ],\n",
              "         [ 96.49756   , 105.49756   , 122.49756   ],\n",
              "         ...,\n",
              "         [177.99797   , 149.99797   , 125.99797   ],\n",
              "         [201.5835    , 173.5835    , 149.5835    ],\n",
              "         [194.93457   , 164.93457   , 153.93457   ]],\n",
              "\n",
              "        [[124.87064   , 133.87064   , 150.87064   ],\n",
              "         [ 96.88737   , 105.88737   , 122.88737   ],\n",
              "         [120.004074  , 117.004074  , 138.00407   ],\n",
              "         ...,\n",
              "         [169.54831   , 152.54831   , 136.54831   ],\n",
              "         [151.70413   , 132.70413   , 126.649445  ],\n",
              "         [156.67256   , 137.67256   , 131.67256   ]]],\n",
              "\n",
              "\n",
              "       [[[132.1674    , 132.1674    , 132.1674    ],\n",
              "         [127.86124   , 129.86124   , 116.86124   ],\n",
              "         [157.82254   , 150.82254   , 131.82254   ],\n",
              "         ...,\n",
              "         [127.94905   , 127.94905   , 127.94905   ],\n",
              "         [148.83168   , 137.94106   , 141.99574   ],\n",
              "         [106.01398   , 106.01398   , 106.01398   ]],\n",
              "\n",
              "        [[169.41629   , 162.41629   , 143.41629   ],\n",
              "         [169.77753   , 162.77753   , 143.77753   ],\n",
              "         [184.85022   , 169.85022   , 140.85022   ],\n",
              "         ...,\n",
              "         [ 80.67277   ,  78.67277   ,  89.67277   ],\n",
              "         [ 97.89171   ,  95.89171   , 106.89171   ],\n",
              "         [ 91.36456   ,  89.36456   , 100.36456   ]],\n",
              "\n",
              "        [[137.74008   , 139.74008   , 126.74009   ],\n",
              "         [166.32303   , 159.26796   , 140.0477    ],\n",
              "         [244.77151   , 216.77151   , 192.77151   ],\n",
              "         ...,\n",
              "         [102.799866  , 100.799866  , 111.799866  ],\n",
              "         [ 75.109375  ,  85.890625  ,  92.        ],\n",
              "         [ 82.77567   ,  79.77567   , 100.77567   ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 70.        ,  79.        ,  96.        ],\n",
              "         [ 70.        ,  79.        ,  95.88986   ],\n",
              "         [ 70.        ,  81.        ,  87.        ],\n",
              "         ...,\n",
              "         [ 53.        ,  53.        ,  53.        ],\n",
              "         [ 45.        ,  56.        ,  62.        ],\n",
              "         [ 45.        ,  56.        ,  62.        ]],\n",
              "\n",
              "        [[ 75.        ,  84.        , 101.        ],\n",
              "         [ 70.        ,  81.        ,  87.        ],\n",
              "         [ 70.        ,  81.        ,  87.        ],\n",
              "         ...,\n",
              "         [ 53.        ,  53.        ,  53.        ],\n",
              "         [ 45.109375  ,  55.890625  ,  62.        ],\n",
              "         [ 45.        ,  56.        ,  62.        ]],\n",
              "\n",
              "        [[ 70.        ,  79.        ,  96.        ],\n",
              "         [ 70.        ,  81.        ,  87.        ],\n",
              "         [ 70.        ,  81.        ,  87.        ],\n",
              "         ...,\n",
              "         [ 53.        ,  53.        ,  53.        ],\n",
              "         [ 53.        ,  53.        ,  53.        ],\n",
              "         [ 45.        ,  57.        ,  53.        ]]],\n",
              "\n",
              "\n",
              "       [[[253.62741   , 244.62741   , 215.62741   ],\n",
              "         [255.        , 241.00764   , 214.00764   ],\n",
              "         [252.78366   , 242.27657   , 211.99023   ],\n",
              "         ...,\n",
              "         [238.89134   , 215.47505   , 175.03012   ],\n",
              "         [239.24055   , 213.66779   , 173.86124   ],\n",
              "         [241.68506   , 213.40753   , 174.5463    ]],\n",
              "\n",
              "        [[254.86888   , 241.86888   , 209.86888   ],\n",
              "         [252.97708   , 237.97708   , 206.97708   ],\n",
              "         [254.        , 239.        , 208.        ],\n",
              "         ...,\n",
              "         [111.03556   ,  91.52391   ,  75.2939    ],\n",
              "         [115.88686   ,  96.7911    ,  82.23932   ],\n",
              "         [118.54529   ,  95.961586  ,  80.92529   ]],\n",
              "\n",
              "        [[254.        , 239.        , 208.        ],\n",
              "         [252.30617   , 238.69383   , 205.        ],\n",
              "         [252.        , 237.        , 204.        ],\n",
              "         ...,\n",
              "         [110.06407   , 100.757904  ,  93.14557   ],\n",
              "         [ 99.51604   ,  90.02867   ,  87.10571   ],\n",
              "         [ 60.94155   ,  60.12759   ,  57.61168   ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[238.21854   , 213.21854   , 172.21854   ],\n",
              "         [239.05507   , 216.05507   , 174.74892   ],\n",
              "         [243.42511   , 220.8128    , 183.50665   ],\n",
              "         ...,\n",
              "         [ 78.649414  ,  99.649414  , 130.64941   ],\n",
              "         [ 54.63839   ,  77.63839   , 111.026085  ],\n",
              "         [ 43.13698   ,  66.13698   , 100.13698   ]],\n",
              "\n",
              "        [[221.67216   , 188.93454   , 145.80334   ],\n",
              "         [222.67522   , 190.74402   , 149.72108   ],\n",
              "         [228.66455   , 199.66455   , 159.66455   ],\n",
              "         ...,\n",
              "         [ 63.148964  ,  85.477715  , 116.477715  ],\n",
              "         [ 55.59094   ,  80.59094   , 111.59094   ],\n",
              "         [ 49.6445    ,  72.6445    , 104.6445    ]],\n",
              "\n",
              "        [[196.08751   , 156.08751   ,  97.        ],\n",
              "         [206.01347   , 166.47765   , 114.32774   ],\n",
              "         [203.069     , 165.93008   , 114.34683   ],\n",
              "         ...,\n",
              "         [ 60.144917  ,  83.14491   , 114.64962   ],\n",
              "         [ 54.116974  ,  81.0076    , 110.06229   ],\n",
              "         [ 51.725048  ,  76.72505   , 107.72505   ]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[ 94.722466  , 132.86124   , 133.5837    ],\n",
              "         [ 85.33453   , 130.33453   , 136.33453   ],\n",
              "         [ 78.73989   , 125.32359   , 135.18483   ],\n",
              "         ...,\n",
              "         [  4.1496515 ,  52.288418  ,  56.427185  ],\n",
              "         [  0.26235503,  48.12106   ,  52.12106   ],\n",
              "         [  5.7224674 ,  56.264942  ,  67.264946  ]],\n",
              "\n",
              "        [[ 98.76342   , 124.44844   , 122.81848   ],\n",
              "         [ 88.635254  , 119.73168   , 121.73168   ],\n",
              "         [ 85.16071   , 118.16071   , 125.16071   ],\n",
              "         ...,\n",
              "         [  1.7894719 ,  42.612625  ,  48.612625  ],\n",
              "         [ 19.04264   ,  57.933266  ,  64.98795   ],\n",
              "         [  0.        ,  43.714813  ,  57.213585  ]],\n",
              "\n",
              "        [[104.13705   , 124.13705   , 123.13705   ],\n",
              "         [ 92.72823   , 117.0726    , 121.0726    ],\n",
              "         [ 88.79775   , 117.79775   , 125.79775   ],\n",
              "         ...,\n",
              "         [  0.        ,  34.768112  ,  39.84961   ],\n",
              "         [  0.        ,  26.361923  ,  32.361923  ],\n",
              "         [  0.47531584,  36.726616  ,  47.394783  ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[174.36122   , 159.36122   , 140.36122   ],\n",
              "         [173.76578   , 158.76578   , 139.76578   ],\n",
              "         [176.79317   , 160.79317   , 144.79317   ],\n",
              "         ...,\n",
              "         [ 30.260109  ,  46.26011   ,  43.26011   ],\n",
              "         [ 24.661339  ,  40.66134   ,  37.66134   ],\n",
              "         [ 16.498047  ,  39.93509   ,  33.93509   ]],\n",
              "\n",
              "        [[180.35078   , 165.35078   , 142.35078   ],\n",
              "         [179.85773   , 164.85773   , 143.85773   ],\n",
              "         [175.13484   , 160.13484   , 141.13484   ],\n",
              "         ...,\n",
              "         [ 41.1392    ,  52.1392    ,  48.1392    ],\n",
              "         [ 37.22346   ,  49.22346   ,  45.22346   ],\n",
              "         [ 28.754427  ,  45.754425  ,  39.754425  ]],\n",
              "\n",
              "        [[172.9533    , 157.9533    , 134.9533    ],\n",
              "         [163.47182   , 153.47182   , 128.47182   ],\n",
              "         [169.27374   , 154.27374   , 131.27374   ],\n",
              "         ...,\n",
              "         [ 35.336845  ,  47.336845  ,  43.336845  ],\n",
              "         [ 36.69787   ,  47.69787   ,  43.69787   ],\n",
              "         [ 41.048534  ,  52.048534  ,  48.048534  ]]],\n",
              "\n",
              "\n",
              "       [[[181.68454   , 184.0109    , 189.33214   ],\n",
              "         [162.5522    , 162.5522    , 170.5522    ],\n",
              "         [166.75082   , 169.75082   , 176.75082   ],\n",
              "         ...,\n",
              "         [244.7016    , 225.97913   , 195.97913   ],\n",
              "         [242.13118   , 223.13118   , 193.13118   ],\n",
              "         [241.55258   , 222.55258   , 192.55258   ]],\n",
              "\n",
              "        [[127.71483   , 131.71483   , 143.        ],\n",
              "         [105.849884  , 109.849884  , 121.849884  ],\n",
              "         [118.919266  , 124.919266  , 138.90164   ],\n",
              "         ...,\n",
              "         [242.75204   , 225.75204   , 195.75204   ],\n",
              "         [244.56093   , 227.56093   , 197.56093   ],\n",
              "         [246.8689    , 227.8689    , 197.8689    ]],\n",
              "\n",
              "        [[113.37004   , 122.31498   , 143.        ],\n",
              "         [115.09099   , 126.09099   , 144.091     ],\n",
              "         [102.72586   , 113.72586   , 134.87564   ],\n",
              "         ...,\n",
              "         [241.30617   , 222.30617   , 189.61234   ],\n",
              "         [245.34412   , 226.34412   , 193.65028   ],\n",
              "         [246.        , 227.        , 194.30617   ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 89.562904  , 126.562904  , 171.5629    ],\n",
              "         [ 99.447105  , 132.50217   , 175.6123    ],\n",
              "         [117.606735  , 146.60674   , 188.60674   ],\n",
              "         ...,\n",
              "         [ 96.88135   , 108.49365   , 128.1875    ],\n",
              "         [193.4255    , 194.4255    , 198.4255    ],\n",
              "         [152.00081   , 155.31575   , 163.3651    ]],\n",
              "\n",
              "        [[ 91.70182   , 128.70183   , 173.70183   ],\n",
              "         [100.361435  , 134.36143   , 180.36143   ],\n",
              "         [123.8689    , 152.8689    , 192.8689    ],\n",
              "         ...,\n",
              "         [101.52086   , 112.52086   , 134.52086   ],\n",
              "         [127.59491   , 130.59491   , 147.65872   ],\n",
              "         [166.62367   , 168.47966   , 171.52605   ]],\n",
              "\n",
              "        [[ 97.18267   , 131.18268   , 177.18268   ],\n",
              "         [ 98.15755   , 130.15756   , 171.15756   ],\n",
              "         [119.81974   , 147.81975   , 187.81975   ],\n",
              "         ...,\n",
              "         [113.78512   , 120.78512   , 139.78513   ],\n",
              "         [101.28104   , 113.09503   , 129.46704   ],\n",
              "         [164.8709    , 166.59306   , 178.31523   ]]],\n",
              "\n",
              "\n",
              "       [[[ 87.29994   , 150.29994   , 193.29994   ],\n",
              "         [217.25113   , 227.53748   , 227.9692    ],\n",
              "         [252.        , 254.        , 249.        ],\n",
              "         ...,\n",
              "         [ 45.20137   ,  61.20137   ,  60.20137   ],\n",
              "         [ 50.12857   ,  66.12857   ,  65.12857   ],\n",
              "         [ 55.749268  ,  67.74927   ,  67.74927   ]],\n",
              "\n",
              "        [[ 87.427315  , 147.47577   , 191.71365   ],\n",
              "         [237.40973   , 242.55508   , 244.12778   ],\n",
              "         [253.98238   , 254.53603   , 249.98238   ],\n",
              "         ...,\n",
              "         [ 52.86328   ,  68.86328   ,  67.86328   ],\n",
              "         [ 53.877075  ,  69.877075  ,  68.877075  ],\n",
              "         [ 35.561367  ,  51.561367  ,  50.561367  ]],\n",
              "\n",
              "        [[ 91.176216  , 146.51788   , 190.64616   ],\n",
              "         [246.1303    , 249.02158   , 250.59724   ],\n",
              "         [251.87308   , 254.38939   , 249.37527   ],\n",
              "         ...,\n",
              "         [ 38.56218   ,  54.56218   ,  53.56218   ],\n",
              "         [ 39.252033  ,  55.252033  ,  54.252033  ],\n",
              "         [ 45.824924  ,  61.824924  ,  60.824924  ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 77.25122   , 128.25122   , 173.25122   ],\n",
              "         [ 62.329056  , 113.32905   , 158.32906   ],\n",
              "         [ 55.33491   , 102.334915  , 148.33492   ],\n",
              "         ...,\n",
              "         [ 65.18945   ,  52.189453  ,  44.189453  ],\n",
              "         [ 61.251328  ,  48.251328  ,  40.251328  ],\n",
              "         [ 63.94278   ,  50.94278   ,  42.94278   ]],\n",
              "\n",
              "        [[ 69.40864   , 119.95942   , 167.85786   ],\n",
              "         [ 67.70572   , 118.2565    , 166.15494   ],\n",
              "         [ 62.586807  , 109.22268   , 156.31505   ],\n",
              "         ...,\n",
              "         [ 58.65513   ,  45.65513   ,  37.65513   ],\n",
              "         [ 60.608902  ,  50.456795  ,  41.61439   ],\n",
              "         [ 64.39427   ,  51.394268  ,  43.394268  ]],\n",
              "\n",
              "        [[ 70.81057   , 120.81057   , 171.81058   ],\n",
              "         [ 69.718056  , 119.718056  , 170.71805   ],\n",
              "         [ 63.57426   , 109.76368   , 158.1954    ],\n",
              "         ...,\n",
              "         [ 62.810547  ,  49.810547  ,  41.810547  ],\n",
              "         [ 63.607033  ,  54.607033  ,  45.607033  ],\n",
              "         [ 59.04883   ,  46.04883   ,  38.04883   ]]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# frquency = 100\n",
        "# target sparsity = 50%\n",
        "# sparisty for each pruning tep = 50%/100 = 0.05%\n",
        "# Total Number of Training Samples = 1440\n",
        "# batch size = 32\n",
        "# epochs = 3\n",
        "\n",
        "# possible start and end for the iterative pruning schedule\n",
        "# Number of learning steps = (1440/32)*3 = 135 (15, 120)\n",
        "# Number of learning steps = (1440/32)*4 = 180 (, )\n",
        "# Number of learning steps = (1440/32)*5 = 225 (, )\n",
        "# Number of learning steps = (1440/32)*6 = 270 (, )\n",
        "\n",
        "# iterative_pruning(\n",
        "                  #     model, \n",
        "                  #     initial_sparsity = 0, \n",
        "                  #     final_sparsity   = 0.9, \n",
        "                  #     begin_step       = 0, 600  (~10% of 5625) # pruning early on the pruning schedule to get optimal model size\n",
        "                  #     end_step         = ?, 4500 (~80% of 5625) # pruning only till 80% so that model can still have enough leanring steps to learn and build networks for the data\n",
        "                  #     train_images, \n",
        "                  #     train_labels, \n",
        "                  #     epochs           = 3, no change ? since the Number of Steps per Epoch = (Total Number of Training Samples = ?) / (Batch Size = ?) \n",
        "                  # )\n",
        "\n",
        "pruned_model_saprsity_50, stripped_pruned_model_saprsity_50 = iterative_pruning(final_model, 0, 0.5, 15, 120, x_train_images, x_train_labels, 3)"
      ],
      "metadata": {
        "id": "HuM0MQw98bOn",
        "outputId": "733fdad6-1bde-4797-9c36-eb18819cbe45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-0d3dc8421d33>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                   \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mpruned_model_saprsity_50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstripped_pruned_model_saprsity_50\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterative_pruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-e848ed0509e4>\u001b[0m in \u001b[0;36miterative_pruning\u001b[0;34m(model, initial_sparsity, final_sparsity, begin_step, end_step, train_images, train_labels, epochs)\u001b[0m\n\u001b[1;32m     21\u001b[0m   ]\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   pruned_model.fit(train_images, train_labels, epochs=epochs, validation_split=0.1,\n\u001b[0m\u001b[1;32m     24\u001b[0m                     callbacks=callbacks)\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1850\u001b[0m             )\n\u001b[1;32m   1851\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 160275801\n  y sizes: 1152\nMake sure all arrays contain the same number of samples."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stripped_pruned_model_saprsity_50.save('stripped_pruned_model_saprsity_50.h5')"
      ],
      "metadata": {
        "id": "g3FlKdYN93_C",
        "outputId": "978b0e48-f914-4f66-f6e8-45468b332080",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_model_weights_sparsity(model):\n",
        "\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.layers.Wrapper):\n",
        "            weights = layer.trainable_weights\n",
        "        else:\n",
        "            weights = layer.weights\n",
        "        for weight in weights:\n",
        "            if \"kernel\" not in weight.name or \"centroid\" in weight.name:\n",
        "                continue\n",
        "            weight_size = weight.numpy().size\n",
        "            zero_num = np.count_nonzero(weight == 0)\n",
        "            print(\n",
        "                f\"{weight.name}: {zero_num/weight_size:.2%} sparsity \",\n",
        "                f\"({zero_num}/{weight_size})\",\n",
        "            )\n",
        "\n",
        "\n",
        "print_model_weights_sparsity(pruned_model_saprsity_50)"
      ],
      "metadata": {
        "id": "EIs-x_kdLIBa",
        "outputId": "246d25f8-6740-458f-910b-e773b12cee15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv2d/kernel:0: 0.00% sparsity  (0/34848)\n",
            "conv2d_1/kernel:0: 0.00% sparsity  (0/614400)\n",
            "conv2d_2/kernel:0: 0.00% sparsity  (0/884736)\n",
            "conv2d_3/kernel:0: 0.00% sparsity  (0/1327104)\n",
            "conv2d_4/kernel:0: 0.00% sparsity  (0/884736)\n",
            "dense/kernel:0: 0.00% sparsity  (0/37748736)\n",
            "dense_1/kernel:0: 0.00% sparsity  (0/16777216)\n",
            "dense_2/kernel:0: 0.00% sparsity  (0/4096)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_pruned_50, test_acc_pruned_50 = pruned_model_saprsity_50.evaluate(x_test,  x_test_labels, verbose=0)"
      ],
      "metadata": {
        "id": "ruil9B3BLeQw"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "startTime = time.time()\n",
        "prediction = pruned_model_saprsity_50.predict(x_test)\n",
        "executionTimePruned50 = (time.time() - startTime)/len(x_test)"
      ],
      "metadata": {
        "id": "by95PgEOL90Q",
        "outputId": "9377b945-2bd1-442a-cdc0-5c51bb844213",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 40ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_model_size = get_gzipped_model_size('stripped_pruned_model_saprsity_50.h5')"
      ],
      "metadata": {
        "id": "x9tFiIELMDyK"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\nPruned Model Accuracy:', test_acc_pruned_50*100, '%')\n",
        "print(\"Pruned Model Size: %.2f bytes\" % (pruned_model_size))\n",
        "print(\"Pruned Inference Time is\", executionTimePruned50, \"s\")"
      ],
      "metadata": {
        "id": "kjLmPCF4MHZI",
        "outputId": "07c161c7-24bd-4e97-db15-9f8ab023cde5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pruned Model Accuracy: 43.75 %\n",
            "Pruned Model Size: 244122.00 bytes\n",
            "Pruned Inference Time is 0.01014922559261322 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evulation_df"
      ],
      "metadata": {
        "id": "gXToE5LuMQUK",
        "outputId": "43e736dc-f96a-4209-fbe9-9952de343167",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               index                      0\n",
              "0    Evaluation type             Evualation\n",
              "1  Model Information                     #0\n",
              "2           Accuracy    72.56944179534912 %\n",
              "3               Loss   261.79609298706055 %\n",
              "4         Model Size        659509171 bytes\n",
              "5     Inference Time  4.570444742838542 sec"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-31b0436b-d650-4c8b-a58c-005342f4efd9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Evaluation type</td>\n",
              "      <td>Evualation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Model Information</td>\n",
              "      <td>#0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Accuracy</td>\n",
              "      <td>72.56944179534912 %</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Loss</td>\n",
              "      <td>261.79609298706055 %</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Model Size</td>\n",
              "      <td>659509171 bytes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Inference Time</td>\n",
              "      <td>4.570444742838542 sec</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31b0436b-d650-4c8b-a58c-005342f4efd9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-31b0436b-d650-4c8b-a58c-005342f4efd9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-31b0436b-d650-4c8b-a58c-005342f4efd9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}