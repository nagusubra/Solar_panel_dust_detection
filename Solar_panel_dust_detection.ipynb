{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOF4zSLrZNGbmM0u7ExKBXj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nagusubra/Solar_panel_dust_detection/blob/main/Solar_panel_dust_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install libraries and modules"
      ],
      "metadata": {
        "id": "SQAMdUOp9lRn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PLxJiY6u9Zh0"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow-model-optimization\n",
        "\n",
        "import tempfile\n",
        "from tensorflow import keras\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mounting google drive (if you are using Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WVnbwh-9x2l",
        "outputId": "822dc778-a9fb-46ee-93ec-ea031b65fa4b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from os import listdir\n",
        "# from os.path import isfile, join\n",
        "\n",
        "# mypath = '/content/drive/MyDrive/Solar_panel_dust_detection/dataset_2/dirty'\n",
        "\n",
        "# onlyfiles = [ f  for f in listdir(mypath) if isfile(join(mypath, f))]\n",
        "\n",
        "# onlyfiles"
      ],
      "metadata": {
        "id": "z1LwhLkSBQ3u"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from os import listdir\n",
        "# from os.path import isfile, join\n",
        "\n",
        "# mypath = '/content/drive/MyDrive/Solar_panel_dust_detection/dataset_2/dirty'\n",
        "\n",
        "# onlyfiles = [ os.rename(join(mypath, f), join(mypath, f.split(\".\")[0] + \"_dirty\" + \".jpg\"))  for f in listdir(mypath) if isfile(join(mypath, f))]\n",
        "\n",
        "# onlyfiles"
      ],
      "metadata": {
        "id": "bwArxFhKADwi"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build base model"
      ],
      "metadata": {
        "id": "vfkTB4_DiYTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def SolNet(in_size):\n",
        "  i = Input(in_size)\n",
        "  r = Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3))(i)\n",
        "  r = BatchNormalization()(r)\n",
        "  r = MaxPooling2D(pool_size=(3,3), strides=(2,2))(r)\n",
        "  r = Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\")(r)\n",
        "  r = BatchNormalization()(r)\n",
        "  r = MaxPooling2D(pool_size=(3,3), strides=(2,2))(r)\n",
        "  r = Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\")(r)\n",
        "  r = BatchNormalization()(r)\n",
        "  r = Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\")(r)\n",
        "  r = BatchNormalization()(r)\n",
        "  r = Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\")(r)\n",
        "  r = BatchNormalization()(r)\n",
        "  r = MaxPooling2D(pool_size=(3,3), strides=(2,2))(r)\n",
        "  r = Flatten()(r)\n",
        "  r = Dense(4096, activation='relu')(r)\n",
        "  r = Dropout(0.5)(r)\n",
        "  r = Dense(4096, activation='relu')(r)\n",
        "  r = Dropout(0.5)(r)\n",
        "  o = Dense(1, activation='sigmoid')(r)\n",
        "  SolNet = Model(i, o)\n",
        "  SolNet.save('models/solnet.hdf5')\n",
        "  SolNet.compile(optimizer=Adam(.0001, .8, .9), loss=binary_crossentropy, metrics=['acc'])\n",
        "  SolNet.summary()\n",
        "  return SolNet"
      ],
      "metadata": {
        "id": "4gVkkz__icfY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataset"
      ],
      "metadata": {
        "id": "RNpb99e9_zgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "directory_path = \"/content/drive/MyDrive/Solar_panel_dust_detection/dataset_1\"\n",
        "\n",
        "image_dateset =  tf.keras.utils.image_dataset_from_directory(\n",
        "                                                              directory_path,\n",
        "                                                              labels=\"inferred\",\n",
        "                                                              label_mode=\"categorical\",\n",
        "                                                              class_names=None,\n",
        "                                                              color_mode=\"rgb\",\n",
        "                                                              batch_size=32,\n",
        "                                                              image_size=(256, 256),\n",
        "                                                              shuffle=True,\n",
        "                                                              seed=None,\n",
        "                                                              validation_split=None,\n",
        "                                                              subset=None,\n",
        "                                                              interpolation=\"bilinear\",\n",
        "                                                              follow_links=False,\n",
        "                                                              crop_to_aspect_ratio=False\n",
        "                                                          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHwIx1h6-Vq7",
        "outputId": "436a5e3e-3b83-469d-9f75-a3d52287d29e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 788 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "directory_path = \"/content/drive/MyDrive/Solar_panel_dust_detection/dataset_1\"\n",
        "\n",
        "image_dateset_1 =  tf.keras.utils.image_dataset_from_directory(\n",
        "                                                              directory_path,\n",
        "                                                              labels=\"inferred\",\n",
        "                                                              label_mode=None,\n",
        "                                                              class_names=None,\n",
        "                                                              color_mode=\"rgb\",\n",
        "                                                              batch_size=32,\n",
        "                                                              image_size=(256, 256),\n",
        "                                                              shuffle=True,\n",
        "                                                              seed=None,\n",
        "                                                              validation_split=None,\n",
        "                                                              subset=None,\n",
        "                                                              interpolation=\"bilinear\",\n",
        "                                                              follow_links=False,\n",
        "                                                              crop_to_aspect_ratio=False\n",
        "                                                          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks3z_I4UguSp",
        "outputId": "b30c042c-2f94-424c-f180-b00e12790ca2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 788 files belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(image_dateset)\n",
        "display(image_dateset_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "kIFzdbP4EhnF",
        "outputId": "0b8711e4-3beb-4644-e897-494b62e886d9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None)>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Base Model"
      ],
      "metadata": {
        "id": "4ZeT32zWUEnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, Dropout\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "By8nXysbUW5V"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SolNet(in_size):\n",
        "  i = Input(in_size)\n",
        "  r = Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3))(i)\n",
        "  r = BatchNormalization()(r)\n",
        "  r = MaxPooling2D(pool_size=(3,3), strides=(2,2))(r)\n",
        "  r = Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\")(r)\n",
        "  r = BatchNormalization()(r)\n",
        "  r = MaxPooling2D(pool_size=(3,3), strides=(2,2))(r)\n",
        "  r = Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\")(r)\n",
        "  r = BatchNormalization()(r)\n",
        "  r = Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\")(r)\n",
        "  r = BatchNormalization()(r)\n",
        "  r = Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\")(r)\n",
        "  r = BatchNormalization()(r)\n",
        "  r = MaxPooling2D(pool_size=(3,3), strides=(2,2))(r)\n",
        "  r = Flatten()(r)\n",
        "  r = Dense(4096, activation='relu')(r)\n",
        "  r = Dropout(0.5)(r)\n",
        "  r = Dense(4096, activation='relu')(r)\n",
        "  r = Dropout(0.5)(r)\n",
        "  o = Dense(1, activation='sigmoid')(r)\n",
        "  SolNet = Model(i, o)\n",
        "  SolNet.save('models/solnet.hdf5')\n",
        "  SolNet.compile(optimizer=Adam(.0001, .8, .9), loss=binary_crossentropy, metrics=['acc'])\n",
        "  SolNet.summary()\n",
        "  return SolNet"
      ],
      "metadata": {
        "id": "8nc6lZnKUixz"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate():\n",
        "  path = \"/content/models/solnet.hdf5\"\n",
        "  solnet = load_model(path, compile=False)\n",
        "  # history = solnet.history()\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.title('acc loss vs epoch')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['loss', 'acc'], loc='upper left')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "dnGGfkkgUo63"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Model Size\n",
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)"
      ],
      "metadata": {
        "id": "QA55ZOpsaMiR"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "#location = 'dataset/'\n",
        "location = \"/content/drive/MyDrive/Solar_panel_dust_detection/dataset_1\"\n",
        "label_mode = 'binary'\n",
        "seed = 10 #changed for each fold made manually\n",
        "epochs=30\n",
        "#epochs=5\n",
        "\n",
        "\n",
        "class_names = ['clean', 'dirty']\n",
        "in_size = [227, 227, 3]\n",
        "\n",
        "tr_dataset = image_dataset_from_directory(directory=location, label_mode= label_mode, class_names=class_names,\n",
        "                                          seed=seed, labels='inferred', image_size=in_size[:-1], \n",
        "                                          subset = 'training', batch_size=batch_size, validation_split=.2)\n",
        "\n",
        "val_dataset = image_dataset_from_directory(directory=location, label_mode= label_mode, class_names=class_names,\n",
        "                                          seed=seed, labels='inferred', image_size=in_size[:-1],\n",
        "                                          subset = 'validation', batch_size=batch_size, validation_split=.2)\n",
        "\n",
        "in_size = [227, 227, 3]\n",
        "SolNet = SolNet(in_size)\n",
        "\n",
        "\n",
        "\n",
        "startTime = time.time()\n",
        "history = SolNet.fit(tr_dataset, validation_data=val_dataset, epochs=epochs, batch_size=batch_size)\n",
        "executionTime = (time.time() - startTime)"
      ],
      "metadata": {
        "id": "fNHot2r1TJdo",
        "outputId": "30b0bd74-c504-4102-f363-e2285aad4b05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 788 files belonging to 2 classes.\n",
            "Using 631 files for training.\n",
            "Found 788 files belonging to 2 classes.\n",
            "Using 157 files for validation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 227, 227, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 55, 55, 96)        34944     \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 55, 55, 96)       384       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 27, 27, 96)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 27, 27, 256)       614656    \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 27, 27, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 13, 13, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 13, 13, 384)       885120    \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 13, 13, 384)      1536      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 13, 13, 384)       1327488   \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 13, 13, 384)      1536      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 13, 13, 256)       884992    \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 13, 13, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 6, 6, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 9216)              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 4096)              37752832  \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 4097      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 58,290,945\n",
            "Trainable params: 58,288,193\n",
            "Non-trainable params: 2,752\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "20/20 [==============================] - 238s 10s/step - loss: 1.5903 - acc: 0.6910 - val_loss: 9.7152 - val_acc: 0.3631\n",
            "Epoch 2/30\n",
            "20/20 [==============================] - 237s 11s/step - loss: 0.7846 - acc: 0.8526 - val_loss: 17.4208 - val_acc: 0.3631\n",
            "Epoch 3/30\n",
            "20/20 [==============================] - 234s 10s/step - loss: 0.4792 - acc: 0.8986 - val_loss: 14.2022 - val_acc: 0.3631\n",
            "Epoch 4/30\n",
            "20/20 [==============================] - 233s 10s/step - loss: 0.3765 - acc: 0.9176 - val_loss: 7.3456 - val_acc: 0.3694\n",
            "Epoch 5/30\n",
            "20/20 [==============================] - 221s 9s/step - loss: 0.3662 - acc: 0.9350 - val_loss: 21.1884 - val_acc: 0.3758\n",
            "Epoch 6/30\n",
            "20/20 [==============================] - 232s 10s/step - loss: 0.3013 - acc: 0.9572 - val_loss: 33.4521 - val_acc: 0.3758\n",
            "Epoch 7/30\n",
            "20/20 [==============================] - 219s 9s/step - loss: 0.1960 - acc: 0.9525 - val_loss: 7.9698 - val_acc: 0.3885\n",
            "Epoch 8/30\n",
            "20/20 [==============================] - 233s 10s/step - loss: 0.1907 - acc: 0.9588 - val_loss: 17.9972 - val_acc: 0.3822\n",
            "Epoch 9/30\n",
            "20/20 [==============================] - 219s 9s/step - loss: 0.2159 - acc: 0.9588 - val_loss: 13.2791 - val_acc: 0.3949\n",
            "Epoch 10/30\n",
            "20/20 [==============================] - 213s 9s/step - loss: 0.2291 - acc: 0.9556 - val_loss: 2.2514 - val_acc: 0.7771\n",
            "Epoch 11/30\n",
            " 3/20 [===>..........................] - ETA: 2:50 - loss: 0.1354 - acc: 0.9688"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history)"
      ],
      "metadata": {
        "id": "nfZ33wPvWWQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history)"
      ],
      "metadata": {
        "id": "d4C6_Bb-Yi7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate()"
      ],
      "metadata": {
        "id": "IJOz2CyMbpef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['acc'], label='accuracy')\n",
        "plt.plot(history.history['val_acc'], label = 'val_accuracy')\n",
        "plt.title('model accuracy plot')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss plot')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ei6SYOpNYk0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Inference Time is\", executionTime/60, \"mins\")"
      ],
      "metadata": {
        "id": "4lFSom8Hg-ut"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}